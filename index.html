import { GoogleGenAI } from "@google/genai";
import { Gender } from "../types";

const getSystemInstruction = (gender: Gender) => {
  return `You are a professional makeup artist and image editor. Your task is to modify the provided user photo by applying specific makeup techniques. 
  The user identifies as ${gender}. Adjust the makeup application to be appropriate and flattering for this gender.
  Ensure the skin texture remains realistic. Do not cartoonize the image. Maintain the original identity of the person.
  Output ONLY the modified image.`;
};

// Helper to convert base64 string to just the data part if it has the prefix
const cleanBase64 = (b64: string) => {
  return b64.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, "");
};

interface GenerateMakeupParams {
  originalImage: string; // Base64
  method: 'text' | 'transfer';
  prompt?: string;
  referenceImage?: string; // Base64
  gender: Gender;
}

export const generateMakeup = async ({
  originalImage,
  method,
  prompt,
  referenceImage,
  gender
}: GenerateMakeupParams): Promise<string> => {
  
  const apiKey = process.env.API_KEY;
  if (!apiKey) throw new Error("API Key not found");

  const ai = new GoogleGenAI({ apiKey });

  const model = 'gemini-2.5-flash-image';
  
  let userPrompt = "";
  const parts: any[] = [];

  // 1. Add Original Image
  parts.push({
    inlineData: {
      data: cleanBase64(originalImage),
      mimeType: "image/jpeg" 
    }
  });

  // 2. Add Logic based on method
  if (method === 'transfer' && referenceImage) {
    // Add reference image
    parts.push({
      inlineData: {
        data: cleanBase64(referenceImage),
        mimeType: "image/jpeg"
      }
    });
    userPrompt = "Apply the makeup style seen in the second image onto the person in the first image. Match the lipstick color, eye makeup style, and blush intensity.";
  } else {
    // Text or Preset
    userPrompt = prompt || "Apply a natural makeup look.";
  }

  // Add the text instruction
  parts.push({
    text: userPrompt
  });

  try {
    const response = await ai.models.generateContent({
      model: model,
      contents: {
        parts: parts
      },
      config: {
        systemInstruction: getSystemInstruction(gender),
        // No responseMimeType needed for image generation/editing usually, 
        // but looking for inlineData in response.
      }
    });

    // Extract image from response
    // The model might return text or an image. 
    // For gemini-2.5-flash-image editing, we check candidates.
    const candidates = response.candidates;
    if (candidates && candidates.length > 0) {
      const content = candidates[0].content;
      if (content.parts) {
        for (const part of content.parts) {
          if (part.inlineData && part.inlineData.data) {
            return `data:image/jpeg;base64,${part.inlineData.data}`;
          }
        }
      }
    }
    
    throw new Error("No image generated by the model.");

  } catch (error) {
    console.error("Gemini API Error:", error);
    throw error;
  }
};
